{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a catalog of DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "import io\n",
    "import itertools\n",
    "import lzma\n",
    "import os\n",
    "\n",
    "import pandas\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cr_commit = '59b7db69534d82452883092852382f6374247fa2'\n",
    "jm_commit = 'f46aa0da3b71b48188e882986fadf639740dcdc6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_xz_url(url, **kwargs):\n",
    "    \"\"\"\n",
    "    Read xz-compressed TSV from a URL.\n",
    "    Will no longer be needed in pandas 0.20 (https://git.io/vSaNV)\n",
    "    \"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    buffer = io.BytesIO(response.content)\n",
    "    return pandas.read_table(buffer, compression='xz', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DOI Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book-chapter',\n",
       " 'book-part',\n",
       " 'book-section',\n",
       " 'journal-article',\n",
       " 'proceedings-article',\n",
       " 'reference-entry',\n",
       " 'report',\n",
       " 'standard'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Crossref work types to include\n",
    "path = os.path.join('data', 'crossref-types.tsv')\n",
    "type_df = pandas.read_table(path)\n",
    "type_df = type_df.query(\"include == 1\")\n",
    "keep_types = set(type_df.type_id)\n",
    "keep_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81609016"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Crossref DOI catalog\n",
    "url = f'https://github.com/greenelab/crossref/raw/{cr_commit}/data/doi.tsv.xz'\n",
    "doi_df = (\n",
    "    read_xz_url(url, dtype={'issued': str})\n",
    "    .query(\"type in @keep_types\")\n",
    ")\n",
    "len(doi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>type</th>\n",
       "      <th>issued</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1001/.387</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>2006-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1001/.389</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>2006-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1001/.391</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>2006-02-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            doi             type      issued\n",
       "0  10.1001/.387  journal-article  2006-02-27\n",
       "1  10.1001/.389  journal-article  2006-02-27\n",
       "2  10.1001/.391  journal-article  2006-02-27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doi_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scopus title to DOI mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scopus_id</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12001</td>\n",
       "      <td>10.1002/jeab.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12001</td>\n",
       "      <td>10.1002/jeab.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scopus_id              doi\n",
       "0      12001   10.1002/jeab.1\n",
       "1      12001  10.1002/jeab.10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crossref \n",
    "crossref_dois = set(doi_df.doi)\n",
    "\n",
    "# Read ISSN to DOI mapping\n",
    "url = f'https://github.com/greenelab/crossref/raw/{cr_commit}/data/doi-to-issn.tsv.xz'\n",
    "issn_to_doi_df = (\n",
    "    read_xz_url(url, dtype={'issued': str})\n",
    "    # Filter DOIs for included types\n",
    "    .query(\"doi in @doi_df.doi\")\n",
    ")\n",
    "\n",
    "# Read ISSN to Scopus mapping\n",
    "url = f'https://github.com/dhimmel/journalmetrics/raw/{jm_commit}/data/issn.tsv'\n",
    "issn_to_scopus_df = pandas.read_table(url)\n",
    "\n",
    "# Create a DOI to ISSN mapping\n",
    "scopus_to_doi_df = (\n",
    "    issn_to_scopus_df\n",
    "    .merge(issn_to_doi_df)\n",
    "    [['scopus_id', 'doi']]\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "# Remove large files from memory\n",
    "del issn_to_doi_df\n",
    "del issn_to_scopus_df\n",
    "\n",
    "scopus_to_doi_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('data', 'scopus-title-to-doi-map.tsv.xz')\n",
    "scopus_to_doi_df.to_csv(path, sep='\\t', index=False, compression='xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add binary columns for whether a DOI is in a given corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DOIs which map to a Scopus title\n",
    "doi_df['in_scopus'] = doi_df.doi.isin(scopus_to_doi_df.doi).astype(int)\n",
    "del scopus_to_doi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read Sci-Hub DOIs from Tweet\n",
    "path = os.path.join('download', 'scihub-dois', 'scihub-doi-list.txt.xz')\n",
    "with lzma.open(path, 'rt') as read_file:\n",
    "    scihub_dois = {line.strip() for line in read_file}\n",
    "doi_df['in_scihub_dois'] = doi_df.doi.isin(scihub_dois).astype(int)\n",
    "del scihub_dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DOIs from Sci-Hub logs from 2015-09 to 2016-02\n",
    "path = os.path.join('download', 'scihub-logs', 'scihub-logs-summary_2015-09_2016-02.tsv.xz')\n",
    "with lzma.open(path, 'rt') as read_file:\n",
    "    reader = csv.DictReader(read_file, delimiter='\\t')\n",
    "    scihub_logs = {row['doi'] for row in reader}\n",
    "doi_df['in_scihub_logs'] = doi_df.doi.isin(scihub_logs).astype(int)\n",
    "del scihub_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read DOIs from LibGen scimag\n",
    "path = os.path.join('download', 'libgen', 'tsv', 'libgen-scimag-date-added-2017-04-07.tsv.xz')\n",
    "with lzma.open(path, 'rt') as read_file:\n",
    "    reader = csv.DictReader(read_file, delimiter='\\t')\n",
    "    libgen = {row['doi'] for row in reader}\n",
    "doi_df['in_libgen'] = doi_df.doi.isin(libgen).astype(int)\n",
    "del libgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>type</th>\n",
       "      <th>issued</th>\n",
       "      <th>in_scopus</th>\n",
       "      <th>in_scihub_dois</th>\n",
       "      <th>in_scihub_logs</th>\n",
       "      <th>in_libgen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1001/.387</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>2006-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1001/.389</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>2006-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1001/.391</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>2006-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            doi             type      issued  in_scopus  in_scihub_dois  \\\n",
       "0  10.1001/.387  journal-article  2006-02-27          1               0   \n",
       "1  10.1001/.389  journal-article  2006-02-27          1               0   \n",
       "2  10.1001/.391  journal-article  2006-02-27          1               0   \n",
       "\n",
       "   in_scihub_logs  in_libgen  \n",
       "0               0          0  \n",
       "1               0          0  \n",
       "2               0          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doi_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join('data', 'doi.tsv.xz')\n",
    "doi_df.to_csv(path, sep='\\t', index=False, compression='xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doi               0.000000\n",
       "type              0.000000\n",
       "issued            0.053804\n",
       "in_scopus         0.000000\n",
       "in_scihub_dois    0.000000\n",
       "in_scihub_logs    0.000000\n",
       "in_libgen         0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percent of each column that is missing\n",
    "doi_df.isnull().mean(axis='rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute coverage of each DOI corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_columns = [x for x in doi_df.columns if x.startswith('in_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in_scopus         56442085\n",
       "in_scihub_dois    50156287\n",
       "in_scihub_logs     7424876\n",
       "in_libgen         50684345\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Crossref DOIs in corpus\n",
    "doi_df[corpus_columns].sum(axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in_scopus         0.691616\n",
       "in_scihub_dois    0.614592\n",
       "in_scihub_logs    0.090981\n",
       "in_libgen         0.621063\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percent of Crossref DOIs in corpus\n",
    "doi_df[corpus_columns].mean(axis='rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute pairwise overlap of DOI corpuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_a</th>\n",
       "      <th>corpus_b</th>\n",
       "      <th>a_size</th>\n",
       "      <th>b_size</th>\n",
       "      <th>a_and_b</th>\n",
       "      <th>a_or_b</th>\n",
       "      <th>a_not_b</th>\n",
       "      <th>b_not_a</th>\n",
       "      <th>proportion_a_in_b</th>\n",
       "      <th>proportion_b_in_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in_scopus</td>\n",
       "      <td>in_scihub_dois</td>\n",
       "      <td>56442085</td>\n",
       "      <td>50156287</td>\n",
       "      <td>42393640</td>\n",
       "      <td>64204732</td>\n",
       "      <td>14048445</td>\n",
       "      <td>7762647</td>\n",
       "      <td>0.751100</td>\n",
       "      <td>0.845231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in_scopus</td>\n",
       "      <td>in_scihub_logs</td>\n",
       "      <td>56442085</td>\n",
       "      <td>7424876</td>\n",
       "      <td>6759982</td>\n",
       "      <td>57106979</td>\n",
       "      <td>49682103</td>\n",
       "      <td>664894</td>\n",
       "      <td>0.119768</td>\n",
       "      <td>0.910450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in_scopus</td>\n",
       "      <td>in_libgen</td>\n",
       "      <td>56442085</td>\n",
       "      <td>50684345</td>\n",
       "      <td>42905446</td>\n",
       "      <td>64220984</td>\n",
       "      <td>13536639</td>\n",
       "      <td>7778899</td>\n",
       "      <td>0.760168</td>\n",
       "      <td>0.846523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in_scihub_dois</td>\n",
       "      <td>in_scihub_logs</td>\n",
       "      <td>50156287</td>\n",
       "      <td>7424876</td>\n",
       "      <td>7224520</td>\n",
       "      <td>50356643</td>\n",
       "      <td>42931767</td>\n",
       "      <td>200356</td>\n",
       "      <td>0.144040</td>\n",
       "      <td>0.973016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in_scihub_dois</td>\n",
       "      <td>in_libgen</td>\n",
       "      <td>50156287</td>\n",
       "      <td>50684345</td>\n",
       "      <td>49524258</td>\n",
       "      <td>51316374</td>\n",
       "      <td>632029</td>\n",
       "      <td>1160087</td>\n",
       "      <td>0.987399</td>\n",
       "      <td>0.977112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in_scihub_logs</td>\n",
       "      <td>in_libgen</td>\n",
       "      <td>7424876</td>\n",
       "      <td>50684345</td>\n",
       "      <td>7136578</td>\n",
       "      <td>50972643</td>\n",
       "      <td>288298</td>\n",
       "      <td>43547767</td>\n",
       "      <td>0.961171</td>\n",
       "      <td>0.140804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus_a        corpus_b    a_size    b_size   a_and_b    a_or_b  \\\n",
       "0       in_scopus  in_scihub_dois  56442085  50156287  42393640  64204732   \n",
       "1       in_scopus  in_scihub_logs  56442085   7424876   6759982  57106979   \n",
       "2       in_scopus       in_libgen  56442085  50684345  42905446  64220984   \n",
       "3  in_scihub_dois  in_scihub_logs  50156287   7424876   7224520  50356643   \n",
       "4  in_scihub_dois       in_libgen  50156287  50684345  49524258  51316374   \n",
       "5  in_scihub_logs       in_libgen   7424876  50684345   7136578  50972643   \n",
       "\n",
       "    a_not_b   b_not_a  proportion_a_in_b  proportion_b_in_a  \n",
       "0  14048445   7762647           0.751100           0.845231  \n",
       "1  49682103    664894           0.119768           0.910450  \n",
       "2  13536639   7778899           0.760168           0.846523  \n",
       "3  42931767    200356           0.144040           0.973016  \n",
       "4    632029   1160087           0.987399           0.977112  \n",
       "5    288298  43547767           0.961171           0.140804  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = list()\n",
    "for corpus_a, corpus_b in itertools.combinations(corpus_columns, 2):\n",
    "    row = collections.OrderedDict()\n",
    "    row['corpus_a'] = corpus_a\n",
    "    row['corpus_b'] = corpus_b\n",
    "    series_a = doi_df[corpus_a]\n",
    "    series_b = doi_df[corpus_b]\n",
    "    row['a_size'] = sum(series_a)\n",
    "    row['b_size'] = sum(series_b)\n",
    "    row['a_and_b'] = sum(series_a & series_b)\n",
    "    row['a_or_b'] = sum(series_a | series_b)\n",
    "    row['a_not_b'] = sum((series_a == 1) & (series_b == 0))\n",
    "    row['b_not_a'] = sum((series_a == 0) & (series_b == 1))\n",
    "    row['proportion_a_in_b'] = row['a_and_b'] / row['a_size']\n",
    "    row['proportion_b_in_a'] = row['a_and_b'] / row['b_size']\n",
    "    rows.append(row)\n",
    "\n",
    "pair_df = pandas.DataFrame(rows)\n",
    "pair_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scihub]",
   "language": "python",
   "name": "conda-env-scihub-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
